"""
Script d'installation pour Google Colab
Installe Ollama et configure l'environnement pour la formation RAG
"""

import subprocess
import time
import os
import sys

def install_ollama():
    """Installation d'Ollama sur Google Colab"""
    print("üöÄ Installation d'Ollama...")
    
    try:
        # T√©l√©chargement et installation d'Ollama
        subprocess.run([
            "curl", "-fsSL", "https://ollama.ai/install.sh", "-o", "/tmp/install.sh"
        ], check=True)
        
        subprocess.run(["chmod", "+x", "/tmp/install.sh"], check=True)
        subprocess.run(["/tmp/install.sh"], check=True)
        
        print("‚úÖ Ollama install√© avec succ√®s")
        return True
    except subprocess.CalledProcessError as e:
        print(f"‚ùå Erreur lors de l'installation d'Ollama: {e}")
        return False

def start_ollama_service():
    """D√©marre le service Ollama en arri√®re-plan"""
    print("üîÑ D√©marrage du service Ollama...")
    
    try:
        # D√©marre Ollama en arri√®re-plan
        process = subprocess.Popen(
            ["ollama", "serve"],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            preexec_fn=os.setsid
        )
        
        # Attendre que le service d√©marre
        time.sleep(10)
        
        # V√©rifier si le service fonctionne
        result = subprocess.run(
            ["ollama", "list"],
            capture_output=True,
            text=True,
            timeout=10
        )
        
        if result.returncode == 0:
            print("‚úÖ Service Ollama d√©marr√©")
            return process
        else:
            print("‚ùå √âchec du d√©marrage du service")
            return None
            
    except Exception as e:
        print(f"‚ùå Erreur lors du d√©marrage: {e}")
        return None

def pull_models():
    """T√©l√©charge les mod√®les n√©cessaires"""
    models = ["llama3.2:3b", "nomic-embed-text:latest"]
    
    for model in models:
        print(f"üì• T√©l√©chargement du mod√®le {model}...")
        try:
            result = subprocess.run(
                ["ollama", "pull", model],
                capture_output=True,
                text=True,
                timeout=600  # 10 minutes max par mod√®le
            )
            
            if result.returncode == 0:
                print(f"‚úÖ Mod√®le {model} t√©l√©charg√©")
            else:
                print(f"‚ùå Erreur pour {model}: {result.stderr}")
                
        except subprocess.TimeoutExpired:
            print(f"‚è±Ô∏è Timeout pour le mod√®le {model}")
        except Exception as e:
            print(f"‚ùå Erreur pour {model}: {e}")

def install_python_dependencies():
    """Installe les d√©pendances Python"""
    print("üì¶ Installation des d√©pendances Python...")
    
    dependencies = [
        "streamlit>=1.28.0",
        "faiss-cpu>=1.7.4",
        "numpy>=1.24.0",
        "PyPDF2>=3.0.1",
        "langchain>=0.1.0",
        "scikit-learn>=1.3.0",
        "ollama-python>=0.1.0"
    ]
    
    for dep in dependencies:
        try:
            subprocess.run([sys.executable, "-m", "pip", "install", dep], check=True)
            print(f"‚úÖ {dep.split('>=')[0]} install√©")
        except subprocess.CalledProcessError as e:
            print(f"‚ùå Erreur pour {dep}: {e}")

def setup_colab_environment():
    """Configuration compl√®te de l'environnement Colab"""
    print("üéØ Configuration de l'environnement Google Colab pour RAG PDF Chat")
    print("=" * 60)
    
    # 1. Installation des d√©pendances Python
    install_python_dependencies()
    
    # 2. Installation d'Ollama
    if not install_ollama():
        print("‚ùå Impossible de continuer sans Ollama")
        return False
    
    # 3. D√©marrage du service
    ollama_process = start_ollama_service()
    if not ollama_process:
        print("‚ùå Impossible de d√©marrer le service Ollama")
        return False
    
    # 4. T√©l√©chargement des mod√®les
    pull_models()
    
    print("=" * 60)
    print("üéâ Configuration termin√©e !")
    print("üìù Instructions:")
    print("   1. Ex√©cutez les cellules du notebook dans l'ordre")
    print("   2. Uploadez vos fichiers PDF via l'interface")
    print("   3. Posez vos questions au chatbot")
    print("‚ö†Ô∏è  Note: Le service Ollama tourne en arri√®re-plan")
    
    return True

if __name__ == "__main__":
    setup_colab_environment()
