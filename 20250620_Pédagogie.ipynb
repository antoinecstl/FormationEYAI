{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5vrqz0aS5jm"
      },
      "source": [
        "# ðŸ“˜ Description pÃ©dagogique (non technique)\n",
        "**Cette cellule permet de connecter Google Drive Ã  lâ€™environnement de travail.** Cela permet dâ€™utiliser des fichiers (ex : jeux de donnÃ©es, documents, modÃ¨les) qui sont stockÃ©s dans votre Google Drive directement dans le Notebook.\n",
        "\n",
        "# ðŸ’¡ Pourquoi on fait Ã§a ?\n",
        "Cela Ã©vite de devoir uploader manuellement des fichiers Ã  chaque fois."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CmQxsyVPrpv",
        "outputId": "588eb53c-5853-40f5-9664-bc75fe5abeb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2a7soxaUOy3"
      },
      "source": [
        "# ðŸ“˜ Description pÃ©dagogique (non technique)\n",
        "**Cette cellule permet de changer le dossier de travail du notebook pour aller dans le dossier principal de votre Google Drive** (Mon Drive).\n",
        "Cela facilite l'accÃ¨s direct aux fichiers sans avoir Ã  Ã©crire un chemin complet Ã  chaque fois.\n",
        "\n",
        "# ðŸ’¡ Pourquoi on fait Ã§a ?\n",
        "En changeant de dossier, on peut lire et enregistrer des fichiers (ex : jeux de donnÃ©es, rÃ©sultats, imagesâ€¦) comme si on Ã©tait dÃ©jÃ  dans Google Drive, ce qui simplifie beaucoup les manipulations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0zEle3BP9jN",
        "outputId": "bd9be6a6-2018-4505-fc14-b75da7addc7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "%cd gdrive/MyDrive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fieAI20cUY3e"
      },
      "source": [
        "# ðŸ“˜ Description pÃ©dagogique (non technique)\n",
        "Cette cellule permet de copier un dossier contenant des fichiers depuis GitHub vers lâ€™environnement de travail du notebook.\n",
        "\n",
        "# ðŸ’¡ Pourquoi on fait Ã§a ?\n",
        "GitHub est une plateforme utilisÃ©e pour stocker, partager du code ou des fichiers de projet. Ici, on tÃ©lÃ©charge les ressources nÃ©cessaires Ã  la formation pour pouvoir les utiliser facilement dans les cellules suivantes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaxikizoQODh",
        "outputId": "f2648b55-9866-45a6-e4fd-6e2a7f1527ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'FormationEYAI'...\n",
            "remote: Enumerating objects: 39, done.\u001b[K\n",
            "remote: Counting objects: 100% (39/39), done.\u001b[K\n",
            "remote: Compressing objects: 100% (31/31), done.\u001b[K\n",
            "remote: Total 39 (delta 10), reused 36 (delta 7), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (39/39), 109.35 KiB | 1.07 MiB/s, done.\n",
            "Resolving deltas: 100% (10/10), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/antoinecstl/FormationEYAI.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vu8eqOfLU_Fq"
      },
      "source": [
        "# ðŸ“˜ Description pÃ©dagogique (non technique)\n",
        "Cette cellule permet de se dÃ©placer dans le dossier FormationEYAI que vous venez de tÃ©lÃ©charger depuis GitHub.\n",
        "\n",
        "# ðŸ’¡ Pourquoi on fait Ã§a ?\n",
        "En se plaÃ§ant dans ce dossier, on pourra accÃ©der plus facilement aux fichiers utiles pour la suite de la formation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tmBw54vQtZV",
        "outputId": "a417f0b1-371e-426a-d57e-5d5d3e5b87b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/FormationEYAI\n"
          ]
        }
      ],
      "source": [
        "%cd FormationEYAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzyDRQQYVPsd"
      },
      "source": [
        "# ðŸ“˜ Description pÃ©dagogique (non technique)\n",
        "**Cette cellule permet dâ€™installer automatiquement tous les outils nÃ©cessaires Ã  la formation Ã  partir dâ€™un fichier spÃ©cial appelÃ© requirements.txt.**\n",
        "Ce fichier contient la liste des modules Python dont on aura besoin pour que le code fonctionne.\n",
        "\n",
        "# ðŸ’¡ Pourquoi on fait Ã§a ?\n",
        "PlutÃ´t que dâ€™installer chaque outil un par un, ce fichier centralise tout, ce qui fait gagner du temps et Ã©vite les erreurs dâ€™oubli ou dâ€™incompatibilitÃ©."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTwv_1H2RGRw"
      },
      "outputs": [],
      "source": [
        "%pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7a94dFHVtut"
      },
      "source": [
        "# ðŸ“˜ Description pÃ©dagogique (non technique)\n",
        "Cette cellule tÃ©lÃ©charge et installe Ollama, un outil qui permet de faire tourner des modÃ¨les dâ€™intelligence artificielle (comme des LLMs) localement sur la machine, sans avoir besoin dâ€™une connexion Ã  un service cloud.\n",
        "\n",
        "# ðŸ’¡ Pourquoi on fait Ã§a ?\n",
        "Cela permet de tester des modÃ¨les dâ€™IA de maniÃ¨re autonome, sans dÃ©pendre de services externes. Câ€™est particuliÃ¨rement utile pour des raisons de confidentialitÃ©, de coÃ»t ou de performance locale."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyeSnz3wR3qP"
      },
      "outputs": [],
      "source": [
        "!curl -fsSL https://ollama.com/install.sh | sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nF7e5ksNVvhM"
      },
      "source": [
        "# ðŸ“˜ Description pÃ©dagogique (non technique)\n",
        "Cette cellule sert Ã  lancer le serveur Ollama, câ€™est-Ã -dire Ã  dÃ©marrer lâ€™outil qui fera fonctionner un modÃ¨le dâ€™IA localement.\n",
        "\n",
        "# ðŸ’¡ Pourquoi on fait Ã§a ?\n",
        "Pour interagir avec un modÃ¨le dâ€™intelligence artificielle installÃ© localement, il faut dâ€™abord dÃ©marrer un service qui Â« Ã©coute Â» et attend nos demandes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_nUDGlJSCDp"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "sub = subprocess.Popen(\"ollama serve\", shell=True, stdout=subprocess.PIPE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ns--aRdLVwbF"
      },
      "source": [
        "# ðŸ“˜ Description pÃ©dagogique (non technique)\n",
        "Ces deux commandes permettent de tÃ©lÃ©charger des modÃ¨les dâ€™intelligence artificielle (IA) que lâ€™on utilisera ensuite dans le projet.\n",
        "\n",
        "1.   **llama3.2 :** un modÃ¨le de langage (LLM), capable de rÃ©pondre Ã  des questions, gÃ©nÃ©rer du texte, rÃ©sumer, etc.\n",
        "\n",
        "2.   **nomic-embed-text :** un modÃ¨le qui transforme des textes en Â« vecteurs Â», une forme que les machines peuvent comprendre pour faire des recherches sÃ©mantiques ou des comparaisons de sens.\n",
        "\n",
        "\n",
        "\n",
        "# ðŸ’¡ Pourquoi on fait Ã§a ?\n",
        "Les LLM sont prÃ©-entraÃ®nÃ©s. Pour pouvoir les utiliser, il faut dâ€™abord les tÃ©lÃ©charger sur votre machine, un peu comme si vous installiez une application.\n",
        "\n",
        "Sans cela, le systÃ¨me ne saura pas quel modÃ¨le utiliser, ni comment rÃ©pondre aux questions ou traiter les textes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBmmJZf-SGO5"
      },
      "outputs": [],
      "source": [
        "!ollama pull llama3.2\n",
        "!ollama pull nomic-embed-text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUouUZJ1VxJ1"
      },
      "source": [
        "# ðŸ“˜ Description pÃ©dagogique (non technique)\n",
        "Cette section permet de lancer une interface web (une mini-application) et de la rendre accessible depuis Internet grÃ¢ce Ã  un outil appelÃ© LocalTunnel.\n",
        "\n",
        "Voici ce que chaque ligne fait :\n",
        "\n",
        "`!npm install localtunnel`\n",
        "\n",
        "*   Installe lâ€™outil LocalTunnel, qui va permettre de partager lâ€™application Streamlit via un lien web.\n",
        "\n",
        "`import urllib + print(...)`\n",
        "*   Affiche lâ€™adresse IP publique de votre environnement pour rÃ©fÃ©rence (souvent inutile cÃ´tÃ© utilisateur, mais utile pour des logs ou du debug).\n",
        "\n",
        "`!streamlit run app.py &>/content/logs.txt &`\n",
        "*   Lance lâ€™application Streamlit (app.py) en arriÃ¨re-plan. Câ€™est cette application qui permet d'interagir avec le modÃ¨le IA via une interface utilisateur.\n",
        "\n",
        "`npx localtunnel --port 8501`\n",
        "*   CrÃ©e un lien temporaire et public vers l'application, utilisable depuis nâ€™importe quel navigateur.\n",
        "\n",
        "# ðŸ’¡ Pourquoi on fait Ã§a ?\n",
        "On crÃ©e ici une interface simple et accessible (dans un navigateur) pour interagir avec le modÃ¨le IA, sans Ã©crire de code.\n",
        "Et comme Colab ou certains environnements locaux nâ€™ont pas dâ€™adresse web fixe, LocalTunnel sert de pont entre votre application et le reste du monde."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-0NSfDrSOEY"
      },
      "outputs": [],
      "source": [
        "!npm install localtunnel\n",
        "import urllib\n",
        "print(\"Password/Enpoint IP for localtunnel is:\",urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))\n",
        "!streamlit run app.py &>/content/logs.txt & npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
